<!DOCTYPE html>

<html lang="en">
<head><link href="main.css" rel="stylesheet"/>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Reinforcement Learning</title>
</head>
<body class="text-left blog">
<header><nav>
<a href="index.html">Start</a> |
<a href="nutshell-nl.html">Notendop</a> |
<a href="blogs-nl.html">Blogs</a> |
<a href="in-depth-nl.html" style="background-color: #A7DFAE;">De diepte in</a> |
<a href="about-me-nl.html">Over mij</a> |
<a href="about-you-nl.html">Over jou</a> |
<a class="lang-switch" href="in-depth.html">English</a> |
<a href="contact-nl.html">Contact</a>
</nav>
</header>
<main class="main">
<article class="blog-detail">
<div class="container">
<header>
<h1 class="blog-detail-title">Reinforcement learning</h1>
</header>
<div class="contenttext">
<p>Reinforcement learning is de basis voor enkele van de meest geavanceerde technologieën van vandaag, zoals zelfrijdende auto's, socialemedia‑algoritmen en AI‑tegenstanders in games. Als psycholoog en neurowetenschapper vind ik het extra fascinerend, omdat het leermechanisme het meest lijkt op hoe mensen leren. Waar andere algoritmen patronen vinden in bekende input‑ en outputparen, leert reinforcement learning via een agent die zelf dynamisch omgeving ontdekt. Waar andere algoritmen het juiste “antwoord” schatten, leert een RL‑agent de beste “beslissing”.</p>
<p>Tijd voor een voorbeeld: het spelletje tikkertje. Er zijn twee spelers: de tikker en de loper. Als ze op dezelfde plek eindigen, is er een ‘tik’ en wint de tikker de ronde. Daarna worden de rollen omgedraaid. In plaats van twee kinderen op een speelplaats, spelen twee AI‑agents een digitale versie. Als de agents dicht bij elkaar zijn en de tikker zo beweegt dat het tot een tik leidt, krijgt die een grote beloning van bijvoorbeeld +50 punten. De loper krijgt een straf van −50 punten. Elke zet zonder tik is voor de tikker −1 punt en voor de loper +1 punt. Een agent begint met willekeurige beslissingen en verkent de omgeving. Na elk spel leert hij de patronen tussen toestand, actie en beloning. Daardoor worden de zetten beter. Het algoritme leert te voorspellen wat te doen om de hoogst mogelijke beloning te krijgen en het spel te winnen.</p>
<p>Dus, wat is RL ook alweer? Het is het trainen van zelfstandige AI‑agents in dynamische omgevingen zodat ze de beste beslissingen leren nemen. In een zakelijke context kan dit grootschalig worden ingezet, zoals bij Big Tech of robotica, maar ook kleinschalig binnen bestaande processen. Denk aan taken die simpel lijken, maar te complex zijn voor template‑gebaseerde automatisering. Het mooie is: de AI‑agent kan al snel waarde toevoegen met eenvoudige taken en vervolgens iteratief meegroeien met de organisatie, niet alleen door de taak beter te leren doen, maar ook door steeds complexere beslissingen te nemen.</p>
<h1 class="blog-detail-title">Toegepaste reinforcement learning</h1>
<h2>Case 1 - Gaming agents</h2>
<p>Om een indruk te geven, zal ik de eerste 10 spellen opsommen die zijn gewonnen met reinforcement learning-algoritmes: Backgammon (1992), dammen (1994), RoboCup Soccer Simulation (2003), Atari-spellen uit de jaren ’80 (2013), Go (2016), Dota 2 (2018), StarCraft II (2019), Gran Turismo Sport (2021), Minecraft (2022) en Diplomacy (2022). In de afgelopen drie jaar zijn er nog veel meer spellen geïntroduceerd met autonome AI-tegenstanders die zijn getraind met RL-technieken.</p>
<p>Dat roept de vraag op: waarom worden RL-technieken niet vaker toegepast in live gaming? Multiplayergames die AI-tegenstanders aanbieden, zijn momenteel meestal voorgeprogrammeerd met regels, waardoor ze voorspelbaar reageren. Ik zie dit als een geweldige kans om reinforcement learning te introduceren in gaming: live, autonome AI-tegenstanders die zich menselijk gedragen. Door de meest geavanceerde technieken toe te passen, kunnen meerdere agents hun eigen leertraject volgen, hun eigen strategieën aanleren en daarmee hun eigen “persoonlijkheden” en vaardigheidsniveaus ontwikkelen. Ik geloof dat dit de game-ervaring van spelers enorm kan verbeteren.</p>
<h2>Case 2 - Aanbevelingen</h2>
<p>Om opnieuw een indruk te geven: in 1998 werd het basisalgoritme van reinforcement learning, het Markov Decision Process, door Google gebruikt om webpagina’s te rangschikken in de Google-zoekapplicatie. Sindsdien is RL toegepast voor aanbevelingen op het web (2001), nieuws (2005) en gepersonaliseerde items in webshops (2018). Reinforcement learning ligt aan de basis van alle socialemedia-technologie. Autonome AI-agents doen aan “Feed Ranking” op YouTube, Facebook, Instagram, TikTok, X, Bluesky, en ga zo maar door.</p>
<p>Ik zie voor me dat dezezelfde algoritmes veel dichter bij jou en mij gebracht kunnen worden, door ze kleinschalig te implementeren. Bevat jouw website of applicatie contentaanbevelingen? Een autonome AI-agent kan dat werk doen.</p>
<h2>Case 3 - Robotica</h2>
<p>Het eerste waar we aan denken bij “zelfstandige AI-agents” is een robot die zelfstandig kan lopen en praten. Daarna denken we aan autonome auto’s en autonome drones. De meest geavanceerde autonome algoritmes sorteren ons afval en worden gebruikt in productie en logistieke processen. In deze context moeten fysiek bewegende “ledematen” en voertuigen reageren op onze real-life, vaak complexe en chaotische omgeving. Reinforcement learning kan in deze context worden ingezet om live autonome beslissingen te nemen.</p>
<h2>Case 4 - Optimalisatie</h2>
<p>In veel industrieën kunnen complexe beslissingsproblemen niet efficiënt worden opgelost met traditionele, regelgebaseerde methoden. Dit is precies waar reinforcement learning (RL) zijn kracht toont. Denk aan het beroemde voorbeeld van de match AlphaGo tegen Lee Sedol in 2016. Tijdens het spel deed AlphaGo een zet die zo ongebruikelijk was dat zelfs topdeskundigen dachten dat het een fout was. Maar naarmate het spel vorderde, bleek die zet een meesterlijke strategie te zijn, iets waar geen mens ooit aan had gedacht. Op dezelfde manier kan RL niet-voor de hand liggende oplossingen vinden voor lastige optimalisatie-uitdagingen. Door te leren van trial-and-error worden beslissingen steeds beter in de loop van de tijd. Enkele krachtige toepassingen zijn: Energiekostenoptimalisatie: dynamisch verlagen van kosten op basis van verbruiksprofielen en prijsfluctuaties. Logistieke optimalisatie: het vinden van de meest efficiënte routes en planningen voor leveringen. Resourceplanning: verbeteren van de inzet van tijd, personeel en materialen. Productie- en procesoptimalisatie: real-time aanpassen van werkstromen voor meer efficiëntie. Operationele optimalisatie: het coördineren van meerdere systemen om vertragingen en verspilling te verminderen. Reinforcement learning volgt niet simpelweg regels, het leert ze te slim af te zijn, net zoals AlphaGo dat deed.</p>

<p style="color: #EDF8EE;">.</p>
<p style="color: #EDF8EE;">.</p>
<p style="color: #EDF8EE;">.</p>
</div>
</div>
</article>
</main>
<footer>
<p style="color: #EDF8EE;">.</p>
<a href="contact-nl.html" style="background-color: #A7DFAE;">Neem contact op</br></a>
<p style="color: #EDF8EE;">.</p>
<p>© 2025 Turing Tactics      kvk 97681202      btw NL005282145B80      <a href="tel:+316 45872055">+316 45872055</a>      <a href="mailto:turingtactis@proton.me">turingtactics@proton.me</a>      <a href="https://www.linkedin.com/in/stanny-goffin-249657106/">LinkedIn</a> </p>
</footer>
</body>
</html>
