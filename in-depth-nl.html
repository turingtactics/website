<!DOCTYPE html>

<html lang="en">
<head><link href="main.css" rel="stylesheet"/>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Reinforcement Learning</title>
</head>
<body class="text-left blog">
<header><a href="index.html"><img alt="Site Logo" class="site-logo" src="logo.png"/></a>
<nav>
<a href="index-nl.html">Start</a> |
<a href="pitch-nl.html">Pitch</a> |
<a href="technology-nl.html">De technologie</a> |
<a href="in-depth-nl.html" style="background-color: #A7DFAE;">De diepte in</a> |
<a href="about-me-nl.html">Over mij</a> |
<a href="about-you-nl.html">Over jou</a> |
<a class="lang-switch" href="in-depth.html">English</a> |
<a href="mailto:turingtactis@gmail.com">Contact</a>
</nav>
</header>
<main class="main">
<article class="blog-detail">
<div class="container">
<header>
<h1 class="blog-detail-title">Reinforcement learning</h1>
</header>
<div class="contenttext">
<p>Reinforcement learning is de basis voor enkele van de meest geavanceerde technologieën van vandaag, zoals zelfrijdende auto's, socialemedia‑algoritmen en AI‑tegenstanders in games. Als psycholoog en neurowetenschapper vind ik het extra fascinerend, omdat het leermechanisme het meest lijkt op hoe mensen leren. Waar andere algoritmen patronen vinden in bekende input‑ en outputparen, leert reinforcement learning via een agent die zelf dynamisch omgeving ontdekt. Waar andere algoritmen het juiste “antwoord” schatten, leert een RL‑agent de beste “beslissing”.</p>
<p>Tijd voor een voorbeeld: het spelletje tikkertje. Er zijn twee spelers: de tikker en de loper. Als ze op dezelfde plek eindigen, is er een ‘tik’ en wint de tikker de ronde. Daarna worden de rollen omgedraaid. In plaats van twee mensen op een speelplaats, spelen twee AI‑agenten een digitale versie. Als de agenten dicht bij elkaar zijn en de tikker zo beweegt dat het tot een tik leidt, krijgt die een grote beloning van bijvoorbeeld +51 punten. De loper krijgt een straf van −51 punten. Elke zet zonder tik is voor de tikker −1 punt en voor de loper +1 punt. Een agent begint met willekeurige beslissingen en verkent de omgeving. Na elk spel leert hij de patronen tussen toestand, actie en beloning. Daardoor worden de zetten beter. Het algoritme leert te voorspellen wat te doen om de hoogst mogelijke beloning te krijgen en het spel te winnen.</p>
<p>Dus, wat is RL ook alweer? Het is het trainen van zelfstandige AI‑agenten in dynamische omgevingen zodat ze de beste beslissingen leren nemen. In een zakelijke context kan dit grootschalig worden ingezet, zoals bij Big Tech of robotica, maar ook kleinschalig binnen bestaande processen. Denk aan taken die simpel lijken, maar te complex zijn voor template‑gebaseerde automatisering. Het mooie is: de AI‑agent kan al snel waarde toevoegen met eenvoudige taken en vervolgens iteratief meegroeien met de organisatie, niet alleen door de taak beter te leren doen, maar ook door steeds complexere beslissingen te nemen.</p>
<h1 class="blog-detail-title">Toegepaste reinforcement learning</h1>
<h2>Case 1 - Autonome gaming agents</h2>
<p>Om een indruk te geven, zal ik de eerste 10 spellen opsommen die zijn gewonnen met reinforcement learning-algoritmes: Backgammon (1992), dammen (1994), RoboCup Soccer Simulation (2003), Atari-spellen uit de jaren ’80 (2013), Go (2016), Dota 2 (2018), StarCraft II (2019), Gran Turismo Sport (2021), Minecraft (2022) en Diplomacy (2022). In de afgelopen drie jaar zijn er nog veel meer spellen geïntroduceerd met autonome AI-tegenstanders die zijn getraind met RL-technieken.</p>
<p>Dat roept de vraag op: waarom worden RL-technieken niet vaker toegepast in live gaming? Multiplayergames die AI-tegenstanders aanbieden, zijn momenteel meestal voorgeprogrammeerd met regels, waardoor ze voorspelbaar reageren. Ik zie dit als een geweldige kans om reinforcement learning te introduceren in gaming: live, autonome AI-tegenstanders die zich menselijk gedragen. Door de meest geavanceerde technieken toe te passen, kunnen meerdere agents hun eigen leertraject volgen, hun eigen strategieën aanleren en daarmee hun eigen “persoonlijkheden” en vaardigheidsniveaus ontwikkelen. Ik geloof dat dit de game-ervaring van spelers enorm kan verbeteren.</p>
<h2>Case 2 - Aanbevelingen</h2>
<p>Om opnieuw een indruk te geven: in 1998 werd het basisalgoritme van reinforcement learning, het Markov Decision Process, door Google gebruikt om webpagina’s te rangschikken in de Google-zoekapplicatie. Sindsdien is RL toegepast voor aanbevelingen op het web (2001), nieuws (2005) en gepersonaliseerde items in webshops (2018). Reinforcement learning ligt aan de basis van alle socialemedia-technologie. Autonome AI-agents doen aan “Feed Ranking” op YouTube, Facebook, Instagram, TikTok, X, Bluesky, en ga zo maar door.</p>
<p>Ik zie voor me dat dezezelfde algoritmes veel dichter bij jou en mij gebracht kunnen worden, door ze kleinschalig te implementeren. Bevat jouw website of applicatie contentaanbevelingen? Een autonome AI-agent kan dat werk doen.</p>
<h2>Case 3 - Robotica en logistiek</h2>
<p>Het eerste waar we aan denken bij “zelfstandige AI-agents” is een robot die zelfstandig kan lopen en praten. Daarna denken we aan autonome auto’s en autonome drones. De meest geavanceerde autonome algoritmes sorteren ons afval en worden gebruikt in productie en logistieke processen. In deze context moeten fysiek bewegende “ledematen” en voertuigen reageren op onze real-life, vaak complexe en chaotische omgeving. Reinforcement learning kan in deze context worden ingezet om live autonome beslissingen te nemen.</p>
<p>Ook op veel kleinere schaal, zoals een agent die je verwarming en slimme apparaten in huis aanstuurt. Zo’n agent kan rekening houden met weerpatronen, energieprijzen en de belasting van het elektriciteitsnet om optimaal energie te besparen.</p>
<p style="color: #EDF8EE;">.</p>
<p style="color: #EDF8EE;">.</p>
<p style="color: #EDF8EE;">.</p>
</div>
</div>
</article>
</main>
<footer>
<p style="color: #EDF8EE;">.</p>
<a href="mailto:turingtactis@gmail.com" style="background-color: #A7DFAE;">Neem contact op</br></a>
<p style="color: #EDF8EE;">.</p>
<p>© 2025 Turing Tactics      kvk 97681202      btw NL005282145B80      +316 45872055      turingtactics@gmail.com </p>
</footer>
</body>
</html>
